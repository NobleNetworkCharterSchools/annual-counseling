{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here, we're going to combine multiple files\n",
    "\n",
    "### This file is a quick port of the prior year's process, which was automated with a script and YAML file\n",
    "\n",
    "There are filenames in the yaml file that __need to be updated based on this year's files__ (specifically by incrementing the year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The cells here are mostly just transcriptions of the merge_files.py script in the root directory of this repo\n",
    "\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "SETTINGS_FILE = '../raw_inputs/inputs.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Function definitions ###############\n",
    "### converter functions ###\n",
    "def safe2int(x):\n",
    "    '''converts to int if possible, otherwise is a string'''\n",
    "    try:\n",
    "        return int(x)\n",
    "    except:\n",
    "        return x\n",
    "\n",
    "def safe2f(x):\n",
    "    '''converts to float if possible, otherwise is a string'''\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return x\n",
    "\n",
    "def p2f(x):\n",
    "    '''converts percent string to float number'''\n",
    "    return None if x == 'N/A' else float(x.strip('%'))/100\n",
    "\n",
    "# This dictionary lets the yaml input translate to one of the functions above\n",
    "CONVERTERS = {'safe2int': safe2int,\n",
    "              'safe2f': safe2f,\n",
    "              'p2f': p2f,\n",
    "              }\n",
    "\n",
    "def safe_divide(x):\n",
    "    '''Divides the first element by the second'''\n",
    "    if np.isnan(x[0]) or np.isnan(x[1]) or x[1] == 0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return x[0]/x[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Substantive functions\n",
    "### These are used for processing input files based on settings in the yaml file\n",
    "\n",
    "def read_input_file(filename, params):\n",
    "    \"\"\"Reads an input file into a DataFrame based on the provided parameters\"\"\"\n",
    "    converters = params['converters'].copy()\n",
    "    for key, value in converters.items():\n",
    "        converters[key] = CONVERTERS[value]  # now references actual function\n",
    "    df = pd.read_csv(filename,\n",
    "                       index_col=params['index_col'],\n",
    "                       encoding=params['encoding'],\n",
    "                       na_values=params['na_values'],\n",
    "                       converters=converters)\n",
    "    if 'reduce' in params: # reduce table to those matching this parameter\n",
    "        var, value = params['reduce'].popitem()\n",
    "        return df.loc[df[var] == value]\n",
    "    else:\n",
    "        return df\n",
    "\n",
    "def insert_calc_column(df, input_df, ix, final_label, specs):\n",
    "    '''Processes the insertion of a non-direct pull column into df using\n",
    "    input_df as the raw table read from a file'''\n",
    "    if specs['type'] == 'direct test':\n",
    "        df.insert(ix, final_label, input_df[specs['source']])\n",
    "    elif specs['type'] == 'remap':\n",
    "        df.insert(ix, final_label, input_df[specs['source']].replace(\n",
    "            specs['mapping']))\n",
    "    elif specs['type'] == 'division':\n",
    "        operands = specs['source'].split(sep='/')\n",
    "        new_col = input_df[operands].apply(safe_divide, axis=1)\n",
    "        df.insert(ix, final_label, new_col)\n",
    "    elif specs['type'] == 'constant':\n",
    "        df[final_label] = specs['source']\n",
    "        \n",
    "def process_read_instructions(df_in, columns):\n",
    "    '''Reduces the raw DF (from file) down to a smaller DF based on the\n",
    "    descriptions from the yaml file'''\n",
    "    # First, handle the 'direct pull' columns for the base of the DF\n",
    "    pull_columns = []\n",
    "    pull_column_labels = []\n",
    "    for column in columns: # iterates over the list of columns\n",
    "        for label in column: # iterates over the single key in the dict\n",
    "            if column[label]['type'] == 'direct pull':\n",
    "                pull_column_labels.append(label)\n",
    "                pull_columns.append(column[label]['source'])\n",
    "    df = df_in[pull_columns]\n",
    "    df.columns = pull_column_labels\n",
    "\n",
    "    # Second, insert the more complicated columns in the correct place\n",
    "    for i in range(len(columns)):\n",
    "        column = columns[i]\n",
    "        for label in column: # iterates over the single key in the dict\n",
    "            if column[label]['type'] != 'direct pull':\n",
    "                insert_calc_column(df, df_in, i-1, label, column[label])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################################\n",
      "# Master instructions for creation of directory\n",
      "# Adds filenames in sequence along with the columns to use\n",
      "# for each\n",
      "#\n",
      "# Most of the keys here are based on the arguments for\n",
      "# the pandas.read_csv function\n",
      "#\n",
      "# Where relevant, an \"INCREMENT\" comment appears next\n",
      "# to each line with a dated filename that needs to be\n",
      "# incremented based on the latest file (downloaded in\n",
      "# step 0)\n",
      "########################################################\n",
      "\n",
      "output_file: inputs/College Directory.xlsx\n",
      "output_sheet_name: 'College Directory 2019'  # INCREMENT each year\n",
      "\n",
      "input_details:\n",
      "    - inputs/base_dir.csv:\n",
      "        - file_setup:\n",
      "            index_col: 0\n",
      "            encoding: cp1252\n",
      "            na_values: N/A\n",
      "            converters:\n",
      "                UNITID: safe2int\n",
      "                ZIP: safe2int\n",
      "        - UNITID:\n",
      "            type: index\n",
      "            source: UNITID\n",
      "        - College Name:\n",
      "            type: direct pull\n",
      "            source: INSTNM\n",
      "        - College Edited Name:\n",
      "            type: direct pull\n",
      "            source: CollegeName\n",
      "        - Address:\n",
      "            type: direct test\n",
      "            source: ADDR\n",
      "        - City:\n",
      "            type: direct pull\n",
      "            source: CITY\n",
      "        - State:\n",
      "            type: direct pull\n",
      "            source: STABBR\n",
      "        - ZIP:\n",
      "            type: direct pull\n",
      "            source: ZIP\n",
      "        - HBCU:\n",
      "            type: direct pull\n",
      "            source: HBCU\n",
      "        - Type:\n",
      "            type: direct pull\n",
      "            source: Type\n",
      "        - Aliases:\n",
      "            type: direct pull\n",
      "            source: IALIAS\n",
      "        - System Name:\n",
      "            type: direct pull\n",
      "            source: F1SYSNAM\n",
      "        - Longitude:\n",
      "            type: direct pull\n",
      "            source: LONGITUD\n",
      "        - Latitude:\n",
      "            type: direct pull\n",
      "            source: LATITUDE\n",
      "        - Distance From Chicago:\n",
      "            type: direct pull\n",
      "            source: DistFromChicago\n",
      "        - Barrons Rating:\n",
      "            type: direct pull\n",
      "            source: BarronsRating\n",
      "        - Simple Barrons:\n",
      "            type: direct pull\n",
      "            source: SimpleBarrons\n",
      "\n",
      "    - inputs/ic2017.csv:  # INCREMENT\n",
      "        - file_setup:\n",
      "            index_col: 0\n",
      "            encoding: cp1252\n",
      "            na_values: N/A\n",
      "            converters:\n",
      "                UNITID: safe2int\n",
      "                OPENADMP: safe2int\n",
      "        - UNITID:\n",
      "            type: index\n",
      "            source: UNITID\n",
      "        - Open Admissions:\n",
      "            type: remap\n",
      "            source: OPENADMP\n",
      "            mapping:\n",
      "                1: 'Yes'\n",
      "                2: 'No'\n",
      "                -2: N/A\n",
      "\n",
      "    - inputs/adm2017.csv:  # INCREMENT\n",
      "        - file_setup:\n",
      "            index_col: 0\n",
      "            encoding: cp1252\n",
      "            na_values: N/A\n",
      "            converters:\n",
      "                UNITID: safe2int\n",
      "        - UNITID:\n",
      "            type: index\n",
      "            source: UNITID\n",
      "        - Applicants:\n",
      "            type: direct pull\n",
      "            source: APPLCN\n",
      "        - Accepted:\n",
      "            type: direct pull\n",
      "            source: ADMSSN\n",
      "        - Enrolled:\n",
      "            type: direct pull\n",
      "            source: ENRLT\n",
      "        - '% Apply Accepted':\n",
      "            type: division\n",
      "            source: ADMSSN/APPLCN\n",
      "        - '% Accepted Enroll':\n",
      "            type: division\n",
      "            source: ENRLT/ADMSSN\n",
      "        - '# of SAT takers':\n",
      "            type: direct pull\n",
      "            source: SATNUM\n",
      "        - '# of ACT takers':\n",
      "            type: direct pull\n",
      "            source: ACTNUM\n",
      "        - '% applicants submitting SAT':\n",
      "            type: direct pull\n",
      "            source: SATPCT\n",
      "        - '% applicants submitting ACT':\n",
      "            type: direct pull\n",
      "            source: ACTPCT\n",
      "        - ACT Composite 25:\n",
      "            type: direct pull\n",
      "            source: ACTCM25\n",
      "        - ACT Composite 75:\n",
      "            type: direct pull\n",
      "            source: ACTCM75\n",
      "        - SAT Verbal 25:\n",
      "            type: direct pull\n",
      "            source: SATVR25\n",
      "        - SAT Verbal 75:\n",
      "            type: direct pull\n",
      "            source: SATVR75\n",
      "        - SAT Math 25:\n",
      "            type: direct pull\n",
      "            source: SATMT25\n",
      "        - SAT Math 75:\n",
      "            type: direct pull\n",
      "            source: SATMT75\n",
      "\n",
      "    - inputs/sfa1617.csv:  # INCREMENT\n",
      "        - file_setup:\n",
      "            index_col: 0\n",
      "            encoding: cp1252\n",
      "            na_values: N/A\n",
      "            converters:\n",
      "                UNITID: safe2int\n",
      "        - UNITID:\n",
      "            type: index\n",
      "            source: UNITID\n",
      "        - '% in state':\n",
      "            type: direct pull\n",
      "            source: SCFA12P\n",
      "        - '% out of state':\n",
      "            type: direct pull\n",
      "            source: SCFA13P\n",
      "        - '% Pell':\n",
      "            type: direct pull\n",
      "            source: UPGRNTP\n",
      "        - 'Avg Net Price': #NPIST2 for public, NPGRN2 for private\n",
      "            type: direct pull\n",
      "            source: NPGRN2\n",
      "        - 'Net Price0-30':\n",
      "            type: direct pull\n",
      "            source: NPT412\n",
      "        - 'Net Price30-48':\n",
      "            type: direct pull\n",
      "            source: NPT422\n",
      "        - 'Net Price48-75':\n",
      "            type: direct pull\n",
      "            source: NPT432\n",
      "        - 'Net Price75-110':\n",
      "            type: direct pull\n",
      "            source: NPT442\n",
      "        - 'Net Price110+':\n",
      "            type: direct pull\n",
      "            source: NPT452\n",
      "\n",
      "    - inputs/ef2017a.csv:  # INCREMENT\n",
      "        - file_setup:\n",
      "            index_col: 0\n",
      "            encoding: cp1252\n",
      "            na_values: N/A\n",
      "            reduce:\n",
      "                EFALEVEL: 2\n",
      "            converters:\n",
      "                UNITID: safe2int\n",
      "        - UNITID:\n",
      "            type: index\n",
      "            source: UNITID\n",
      "        - '# of undergraduates':\n",
      "            type: direct pull\n",
      "            source: EFTOTLT\n",
      "        - '% male':\n",
      "            type: division\n",
      "            source: EFTOTLM/EFTOTLT\n",
      "        - '% female':\n",
      "            type: division\n",
      "            source: EFTOTLW/EFTOTLT\n",
      "        - '% AA':\n",
      "            type: division\n",
      "            source: EFBKAAT/EFTOTLT\n",
      "        - '% Hispanic':\n",
      "            type: division\n",
      "            source: EFHISPT/EFTOTLT\n",
      "        - '% AA male':\n",
      "            type: division\n",
      "            source: EFBKAAM/EFTOTLT\n",
      "        - '% AA female':\n",
      "            type: division\n",
      "            source: EFBKAAW/EFTOTLT\n",
      "        - '% Hispanic male':\n",
      "            type: division\n",
      "            source: EFHISPM/EFTOTLT\n",
      "        - '% Hispanic female':\n",
      "            type: division\n",
      "            source: EFHISPW/EFTOTLT\n",
      "\n",
      "    - inputs/grad_rates.csv:\n",
      "        - file_setup:\n",
      "            index_col: 0\n",
      "            encoding: cp1252\n",
      "            na_values: N/A\n",
      "            converters:\n",
      "                UNITID: safe2int\n",
      "                Grad Cohort: safe2int\n",
      "        - UNITID:\n",
      "            type: index\n",
      "            source: UNITID\n",
      "        - Grad Cohort:\n",
      "            type: direct pull\n",
      "            source: GR_Source\n",
      "        - Adj 6yr Grad:\n",
      "            type: direct pull\n",
      "            source: Adj6yrGrad\n",
      "        - Adj 6yr Grad AA_H:\n",
      "            type: direct pull\n",
      "            source: Adj6yrAAH\n",
      "        - 6yr Grad:\n",
      "            type: direct pull\n",
      "            source: 6yrGrad\n",
      "        - 6yr Grad AA_H:\n",
      "            type: direct pull\n",
      "            source: 6yrAAH\n",
      "        - 6yr Grad AA:\n",
      "            type: direct pull\n",
      "            source: 6yrAA\n",
      "        - 6yr Grad H:\n",
      "            type: direct pull\n",
      "            source: 6yrH\n",
      "        - Xfer:\n",
      "            type: direct pull\n",
      "            source: Xfer\n",
      "        - XferAAH:\n",
      "            type: direct pull\n",
      "            source: XferAAH\n",
      "        - XferAA:\n",
      "            type: direct pull\n",
      "            source: XferAA\n",
      "        - XferH:\n",
      "            type: direct pull\n",
      "            source: XferH\n",
      "\n",
      "    - inputs/ef2017d.csv:  # INCREMENT\n",
      "        - file_setup:\n",
      "            index_col: 0\n",
      "            encoding: cp1252\n",
      "            na_values: N/A\n",
      "            converters:\n",
      "                UNITID: safe2int\n",
      "        - UNITID:\n",
      "            type: index\n",
      "            source: UNITID\n",
      "        - Retention:\n",
      "            type: direct pull\n",
      "            source: RET_PCF\n",
      "        - AdjACT25:  # These next 7 will be calculated manually\n",
      "            type: constant\n",
      "            source: 0.0\n",
      "        - AdjACT50:\n",
      "            type: constant\n",
      "            source: 0.0\n",
      "        - AdjACT75:\n",
      "            type: constant\n",
      "            source: 0.0\n",
      "        - AdjSAT25:\n",
      "            type: constant\n",
      "            source: 0.0\n",
      "        - AdjSAT50:\n",
      "            type: constant\n",
      "            source: 0.0\n",
      "        - AdjSAT75:\n",
      "            type: constant\n",
      "            source: 0.0\n",
      "        - Estimated AA_H Retention:\n",
      "            type: constant\n",
      "            source: 0.0\n",
      "\n",
      "    - inputs/hd2017.csv:  # INCREMENT\n",
      "        - file_setup:\n",
      "            index_col: 0\n",
      "            encoding: cp1252\n",
      "            na_values: N/A\n",
      "            converters:\n",
      "                UNITID: safe2int\n",
      "        - UNITID:\n",
      "            type: index\n",
      "            source: UNITID\n",
      "        - Carnegie Code:\n",
      "            type: remap\n",
      "            source: C15BASIC\n",
      "            mapping:\n",
      "                1: \"Associate's Colleges: High Transfer-High Traditional\"\n",
      "                2: \"Associate's Colleges: High Transfer-Mixed Traditional/Nontraditional\"\n",
      "                3: \"Associate's Colleges: High Transfer-High Nontraditional\"\n",
      "                4: \"Associate's Colleges: Mixed Transfer/Career & Technical-High Traditional\"\n",
      "                5: \"Associate's Colleges: Mixed Transfer/Career & Technical-Mixed Traditional/Nontraditional\"\n",
      "                6: \"Associate's Colleges: Mixed Transfer/Career & Technical-High Nontraditional\"\n",
      "                7: \"Associate's Colleges: High Career & Technical-High Traditional\"\n",
      "                8: \"Associate's Colleges: High Career & Technical-Mixed Traditional/Nontraditional\"\n",
      "                9: \"Associate's Colleges: High Career & Technical-High Nontraditional\"\n",
      "                10: \"Special Focus Two-Year: Health Professions\"\n",
      "                11: \"Special Focus Two-Year: Technical Professions\"\n",
      "                12: \"Special Focus Two-Year: Arts & Design\"\n",
      "                13: \"Special Focus Two-Year: Other Fields\"\n",
      "                14: \"Baccalaureate/Associate's Colleges: Associate's Dominant\"\n",
      "                15: \"Doctoral Universities: Highest Research Activity\"\n",
      "                16: \"Doctoral Universities: Higher Research Activity\"\n",
      "                17: \"Doctoral Universities: Moderate Research Activity\"\n",
      "                18: \"Master's Colleges & Universities: Larger Programs\"\n",
      "                19: \"Master's Colleges & Universities: Medium Programs\"\n",
      "                20: \"Master's Colleges & Universities: Small Programs\"\n",
      "                21: \"Baccalaureate Colleges: Arts & Sciences Focus\"\n",
      "                22: \"Baccalaureate Colleges: Diverse Fields\"\n",
      "                23: \"Baccalaureate/Associate's Colleges: Mixed Baccalaureate/Associate's\"\n",
      "                24: \"Special Focus Four-Year: Faith-Related Institutions\"\n",
      "                25: \"Special Focus Four-Year: Medical Schools & Centers\"\n",
      "                26: \"Special Focus Four-Year: Other Health Professions Schools\"\n",
      "                27: \"Special Focus Four-Year: Engineering Schools\"\n",
      "                28: \"Special Focus Four-Year: Other Technology-Related Schools\"\n",
      "                29: \"Special Focus Four-Year: Business & Management Schools\"\n",
      "                30: \"Special Focus Four-Year: Arts, Music & Design Schools\"\n",
      "                31: \"Special Focus Four-Year: Law Schools\"\n",
      "                32: \"Special Focus Four-Year: Other Special Focus Institutions\"\n",
      "                33: \"Tribal Colleges\"\n",
      "                -2: \"Not applicable, not in Carnegie universe (not accredited or nondegree-granting)\"\n",
      "        - Locale:\n",
      "            type: remap\n",
      "            source: LOCALE\n",
      "            mapping:\n",
      "                11: \"City: Large\"\n",
      "                12: \"City: Midsize\"\n",
      "                13: \"City: Small\"\n",
      "                21: \"Suburb: Large\"\n",
      "                22: \"Suburb: Midsize\"\n",
      "                23: \"Suburb: Small\"\n",
      "                31: \"Town: Fringe\"\n",
      "                32: \"Town: Distant\"\n",
      "                33: \"Town: Remote\"\n",
      "                41: \"Rural: Fringe\"\n",
      "                42: \"Rural: Distant\"\n",
      "                43: \"Rural: Remote\"\n",
      "                -3: \"N/A\"\n",
      "        - Locale short:\n",
      "            type: remap\n",
      "            source: LOCALE\n",
      "            mapping:\n",
      "                11: \"city-based\"\n",
      "                12: \"city-based\"\n",
      "                13: \"city-based\"\n",
      "                21: \"suburban\"\n",
      "                22: \"suburban\"\n",
      "                23: \"suburban\"\n",
      "                31: \"town-based\"\n",
      "                32: \"town-based\"\n",
      "                33: \"town-based\"\n",
      "                41: \"rural\"\n",
      "                42: \"rural\"\n",
      "                43: \"rural\"\n",
      "                -3: \"N/A\"\n",
      "        - Size Range:  # Will be calculated manually\n",
      "            type: constant\n",
      "            source: 0.0\n",
      "        - Website:\n",
      "            type: direct pull\n",
      "            source: WEBADDR\n",
      "        - OPEID:\n",
      "            type: direct pull\n",
      "            source: OPEID\n",
      "        - Sector:\n",
      "            type: remap\n",
      "            source: SECTOR\n",
      "            mapping:\n",
      "                0: \"Administrative Unit\"\n",
      "                1: \"Public, 4-year or above\"\n",
      "                2: \"Private not-for-profit, 4-year or above\"\n",
      "                3: \"Private for-profit, 4-year or above\"\n",
      "                4: \"Public, 2-year\"\n",
      "                5: \"Private not-for-profit, 2-year\"\n",
      "                6: \"Private for-profit, 2-year\"\n",
      "                7: \"Public, less-than 2-year\"\n",
      "                8: \"Private not-for-profit, less-than 2-year\"\n",
      "                9: \"Private for-profit, less-than 2-year\"\n",
      "                99: \"N/A\"\n",
      "\n",
      "    - ../raw_inputs/extra_directory_info.csv:\n",
      "        - file_setup:\n",
      "            index_col: 0\n",
      "            encoding: cp1252\n",
      "            na_values: N/A\n",
      "            converters:\n",
      "                UNITID: safe2int\n",
      "        - UNITID:\n",
      "            type: index\n",
      "            source: UNITID\n",
      "        - CEEB Code:\n",
      "            type: direct pull\n",
      "            source: CEEB\n",
      "        - ACT Code:\n",
      "            type: direct pull\n",
      "            source: ACT\n",
      "        - 'ACI?':\n",
      "            type: direct pull\n",
      "            source: ACI\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This is the settings file specifying the details of the merge\n",
    "# Edit it directly to fix the year of the latest files (there is an \"INCREMENT\" comment where this is required)\n",
    "with open(SETTINGS_FILE) as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From here below actually runs all of this setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading configuration file...\n"
     ]
    }
   ],
   "source": [
    "####### Main script ####################\n",
    "print('Loading configuration file...')\n",
    "with open(SETTINGS_FILE, 'r') as ymlfile:\n",
    "    cfg = yaml.load(ymlfile)\n",
    "\n",
    "df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file (inputs/base_dir.csv)\n",
      "Reading file (inputs/ic2017.csv)\n",
      "Reading file (inputs/adm2017.csv)\n",
      "Reading file (inputs/sfa1617.csv)\n",
      "Reading file (inputs/ef2017a.csv)\n",
      "Reading file (inputs/grad_rates.csv)\n",
      "Reading file (inputs/ef2017d.csv)\n",
      "Reading file (inputs/hd2017.csv)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\mniksch\\dropbox (nnocs)\\documents\\noblegit\\venvs\\annual\\lib\\site-packages\\ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file (../raw_inputs/extra_directory_info.csv)\n"
     ]
    }
   ],
   "source": [
    "for file in cfg['input_details']:\n",
    "    filename, details = file.popitem()\n",
    "    print('Reading file ({})'.format(filename),flush=True)\n",
    "    \n",
    "    this_df = read_input_file(filename, details[0]['file_setup'])\n",
    "    sliced_df = process_read_instructions(this_df, details[1:])\n",
    "    \n",
    "    if type(df) is not pd.DataFrame:\n",
    "        df = sliced_df\n",
    "    else:\n",
    "        df = pd.concat([df, sliced_df], axis=1, join_axes=[df.index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## After the raw data has been loaded and combined, there are a few manipulations\n",
    "\n",
    "### In order, we'll do:\n",
    "\n",
    "1. Calculation of AdjACT25, 50, and 75 fields (which add converted SAT to low ACT schools)\n",
    "2. Calculation of AdjSAT25, 50, and 75 fields (which add converted ACT to low SAT schools)\n",
    "3. Size Range\n",
    "4. Estimated AA_H retention--based on a formula and the gap between AA/H and Overall grad rates and Retention (will be 0-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we'll create \"AdjACT25, 50, and 75\" fields for admissions analyses\n",
    "# Next AdjACT25, 50, and 75\n",
    "admissions_file = 'inputs/adm2017.csv'  # INCREMENT\n",
    "sat_to_act_file = '../raw_inputs/sat_to_act.csv'\n",
    "adm_fields = ['APPLCN','ADMSSN',\n",
    "              'SATPCT','ACTPCT',\n",
    "              'SATVR25','SATVR75','SATMT25','SATMT75',\n",
    "              'ACTCM25','ACTCM75']\n",
    "adm_df = pd.read_csv(admissions_file, index_col=['UNITID'],\n",
    "                     usecols=['UNITID']+adm_fields,\n",
    "                     na_values='.',\n",
    "                     encoding='latin-1')\n",
    "sat_to_act = pd.read_csv(sat_to_act_file, index_col=['SAT'],dtype={'SAT':int,'ACT':int},encoding='cp1252')\n",
    "adm_df['pct_accepted'] = adm_df.ADMSSN/adm_df.APPLCN\n",
    "\n",
    "def calculate_adjact25_50_75(df):\n",
    "    \"\"\"\n",
    "    Estimates the median 'ACT' based on 25th to 75th percentile range of either ACT\n",
    "    or converted SAT\n",
    "    \"\"\"\n",
    "    adj25, adj50, adj75 = (np.nan, np.nan, np.nan)\n",
    "    if df.ACTPCT >= 20 and np.isfinite(df.ACTCM25) and np.isfinite(df.ACTCM75): #reasonable number of ACT\n",
    "        adj25 = df.ACTCM25\n",
    "        adj75 = df.ACTCM75\n",
    "        adj50 = (adj25 + adj75)/2\n",
    "    elif df.SATPCT >= 20 and (np.isfinite(df.SATVR25) and np.isfinite(df.SATMT25) and\n",
    "                              np.isfinite(df.SATVR75) and np.isfinite(df.SATMT75)): #same threshold for SAT\n",
    "        sat25 = int(np.round(df.SATVR25+df.SATMT25,decimals=-1))\n",
    "        sat75 = int(np.round(df.SATVR75+df.SATMT75,decimals=-1))\n",
    "        adj25 = sat_to_act.ACT[sat25]\n",
    "        adj75 = sat_to_act.ACT[sat75]\n",
    "        adj50 = (adj25 + adj75)/2\n",
    "    return (adj25, adj50, adj75)\n",
    "\n",
    "adm_df[['AdjACT25','AdjACT50','AdjACT75']] = adm_df.apply(calculate_adjact25_50_75,axis=1,result_type='expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLCN</th>\n",
       "      <th>ADMSSN</th>\n",
       "      <th>SATPCT</th>\n",
       "      <th>ACTPCT</th>\n",
       "      <th>SATVR25</th>\n",
       "      <th>SATVR75</th>\n",
       "      <th>SATMT25</th>\n",
       "      <th>SATMT75</th>\n",
       "      <th>ACTCM25</th>\n",
       "      <th>ACTCM75</th>\n",
       "      <th>pct_accepted</th>\n",
       "      <th>AdjACT25</th>\n",
       "      <th>AdjACT50</th>\n",
       "      <th>AdjACT75</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UNITID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111966</th>\n",
       "      <td>61</td>\n",
       "      <td>55.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>588.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.901639</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118693</th>\n",
       "      <td>2524</td>\n",
       "      <td>1085.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>498.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.429873</td>\n",
       "      <td>19.0</td>\n",
       "      <td>21.5</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119173</th>\n",
       "      <td>2352</td>\n",
       "      <td>1910.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>570.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>550.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.812075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>19.5</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120537</th>\n",
       "      <td>786</td>\n",
       "      <td>223.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>550.0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>550.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.283715</td>\n",
       "      <td>16.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128498</th>\n",
       "      <td>933</td>\n",
       "      <td>596.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>410.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.638800</td>\n",
       "      <td>14.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        APPLCN  ADMSSN  SATPCT  ACTPCT  SATVR25  SATVR75  SATMT25  SATMT75  \\\n",
       "UNITID                                                                       \n",
       "111966      61    55.0    38.0     0.0    510.0    620.0    565.0    588.0   \n",
       "118693    2524  1085.0    34.0    11.0    498.0    585.0    510.0    580.0   \n",
       "119173    2352  1910.0    89.0    15.0    470.0    570.0    450.0    550.0   \n",
       "120537     786   223.0    81.0    17.0    450.0    550.0    460.0    550.0   \n",
       "128498     933   596.0    93.0     0.0    410.0    540.0    400.0    510.0   \n",
       "\n",
       "        ACTCM25  ACTCM75  pct_accepted  AdjACT25  AdjACT50  AdjACT75  \n",
       "UNITID                                                                \n",
       "111966      NaN      NaN      0.901639      21.0      23.0      25.0  \n",
       "118693     18.0     25.0      0.429873      19.0      21.5      24.0  \n",
       "119173     16.0     21.0      0.812075      17.0      19.5      22.0  \n",
       "120537     17.0     26.0      0.283715      16.0      19.0      22.0  \n",
       "128498      NaN      NaN      0.638800      14.0      17.0      20.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visually inspect the first few converted rows (looking for AdjACT25, 50, 75 values:\n",
    "adm_df[adm_df['ACTPCT']<20].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now add them to the main DF\n",
    "for var in ['AdjACT25','AdjACT50','AdjACT75']:\n",
    "    df[var] = df.index.map(lambda x: adm_df[var].get(x, default=np.nan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second, we'll follow exactly the same process to create similar variables for SAT\n",
    "admissions_file = 'inputs/adm2017.csv'  # INCREMENT\n",
    "act_to_sat_file = '../raw_inputs/act_to_sat.csv'\n",
    "adm_fields = ['APPLCN','ADMSSN',\n",
    "              'SATPCT','ACTPCT',\n",
    "              'SATVR25','SATVR75','SATMT25','SATMT75',\n",
    "              'ACTCM25','ACTCM75']\n",
    "adm_df = pd.read_csv(admissions_file, index_col=['UNITID'],\n",
    "                     usecols=['UNITID']+adm_fields,\n",
    "                     na_values='.',\n",
    "                     encoding='latin-1')\n",
    "act_to_sat = pd.read_csv(act_to_sat_file, index_col=['ACT'],dtype={'SAT':int,'ACT':int},encoding='cp1252')\n",
    "adm_df['pct_accepted'] = adm_df.ADMSSN/adm_df.APPLCN\n",
    "\n",
    "def calculate_adjsat25_50_75(df):\n",
    "    \"\"\"\n",
    "    Estimates the median 'SAT' based on 25th to 75th percentile range of either SAT\n",
    "    or converted ACT\n",
    "    \"\"\"\n",
    "    adj25, adj50, adj75 = (np.nan, np.nan, np.nan)\n",
    "    if df.SATPCT >= 20 and (np.isfinite(df.SATVR25) and np.isfinite(df.SATMT25) and\n",
    "                              np.isfinite(df.SATVR75) and np.isfinite(df.SATMT75)):  # reasonable threshold\n",
    "        adj25 = int(np.round(df.SATVR25+df.SATMT25,decimals=-1))\n",
    "        adj75 = int(np.round(df.SATVR75+df.SATMT75,decimals=-1))\n",
    "        adj50 = (adj25 + adj75)/2\n",
    "    elif df.ACTPCT >= 20 and np.isfinite(df.ACTCM25) and np.isfinite(df.ACTCM75):  # same cutoff for ACT\n",
    "        act25 = int(df.ACTCM25)\n",
    "        act75 = int(df.ACTCM75)\n",
    "        try:\n",
    "            adj25 = int(act_to_sat.SAT[int(act25)])\n",
    "        except KeyError as e:\n",
    "            if act25 < min(act_to_sat.index):  # If they reported an impossibly low score, correct\n",
    "                adj25 = act_to_sat.SAT[min(act_to_sat.index)]\n",
    "            else:\n",
    "                raise e\n",
    "        adj75 = int(act_to_sat.SAT[act75])\n",
    "        adj50 = int((adj25 + adj75)/2)\n",
    "    \n",
    "    return (adj25, adj50, adj75)\n",
    "\n",
    "adm_df[['AdjSAT25','AdjSAT50','AdjSAT75']] = adm_df.apply(calculate_adjsat25_50_75,axis=1,result_type='expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLCN</th>\n",
       "      <th>ADMSSN</th>\n",
       "      <th>SATPCT</th>\n",
       "      <th>ACTPCT</th>\n",
       "      <th>SATVR25</th>\n",
       "      <th>SATVR75</th>\n",
       "      <th>SATMT25</th>\n",
       "      <th>SATMT75</th>\n",
       "      <th>ACTCM25</th>\n",
       "      <th>ACTCM75</th>\n",
       "      <th>pct_accepted</th>\n",
       "      <th>AdjSAT25</th>\n",
       "      <th>AdjSAT50</th>\n",
       "      <th>AdjSAT75</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UNITID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100654</th>\n",
       "      <td>8610</td>\n",
       "      <td>7772.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>485.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>495.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.902671</td>\n",
       "      <td>890.0</td>\n",
       "      <td>950.0</td>\n",
       "      <td>1010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100663</th>\n",
       "      <td>7555</td>\n",
       "      <td>6936.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>630.0</td>\n",
       "      <td>550.0</td>\n",
       "      <td>740.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.918068</td>\n",
       "      <td>1080.0</td>\n",
       "      <td>1195.0</td>\n",
       "      <td>1310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100706</th>\n",
       "      <td>4454</td>\n",
       "      <td>3618.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>550.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>530.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.812304</td>\n",
       "      <td>1210.0</td>\n",
       "      <td>1305.0</td>\n",
       "      <td>1400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100724</th>\n",
       "      <td>6842</td>\n",
       "      <td>6696.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>485.0</td>\n",
       "      <td>375.0</td>\n",
       "      <td>481.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.978661</td>\n",
       "      <td>890.0</td>\n",
       "      <td>965.0</td>\n",
       "      <td>1040.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100751</th>\n",
       "      <td>38129</td>\n",
       "      <td>20321.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>530.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.532954</td>\n",
       "      <td>1140.0</td>\n",
       "      <td>1285.0</td>\n",
       "      <td>1430.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        APPLCN   ADMSSN  SATPCT  ACTPCT  SATVR25  SATVR75  SATMT25  SATMT75  \\\n",
       "UNITID                                                                        \n",
       "100654    8610   7772.0     1.0    88.0    365.0    485.0    360.0    495.0   \n",
       "100663    7555   6936.0     1.0    94.0    440.0    630.0    550.0    740.0   \n",
       "100706    4454   3618.0     2.0    96.0    550.0    660.0    530.0    670.0   \n",
       "100724    6842   6696.0    18.0    85.0    380.0    485.0    375.0    481.0   \n",
       "100751   38129  20321.0    19.0    81.0    530.0    640.0    520.0    640.0   \n",
       "\n",
       "        ACTCM25  ACTCM75  pct_accepted  AdjSAT25  AdjSAT50  AdjSAT75  \n",
       "UNITID                                                                \n",
       "100654     16.0     19.0      0.902671     890.0     950.0    1010.0  \n",
       "100663     21.0     28.0      0.918068    1080.0    1195.0    1310.0  \n",
       "100706     25.0     31.0      0.812304    1210.0    1305.0    1400.0  \n",
       "100724     16.0     20.0      0.978661     890.0     965.0    1040.0  \n",
       "100751     23.0     32.0      0.532954    1140.0    1285.0    1430.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visually inspect the first few converted rows (looking for AdjSAT25, 50, 75 values:\n",
    "adm_df[adm_df['SATPCT']<20].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now add them to the main DF\n",
    "for var in ['AdjSAT25','AdjSAT50','AdjSAT75']:\n",
    "    df[var] = df.index.map(lambda x: adm_df[var].get(x, default=np.nan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third, we'll calculate Size Range\n",
    "def return_size_range(num_ug):\n",
    "    \"\"\"Apply function to give a text response for Size Range\"\"\"\n",
    "    if np.isnan(num_ug):\n",
    "        return 'N/A'\n",
    "    else:\n",
    "        if num_ug >= 20000:\n",
    "            return '20,000 and above'\n",
    "        elif num_ug >= 10000:\n",
    "            return '10,000-19,999'\n",
    "        elif num_ug >= 5000:\n",
    "            return '5,000-9,999'\n",
    "        elif num_ug >= 1000:\n",
    "            return '1,000-4,999'\n",
    "        else:\n",
    "            return 'Under 1,000'\n",
    "df['Size Range'] = df['# of undergraduates'].apply(return_size_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fourth, estimated AA/H retention\n",
    "def calc_aa_h_retention(x):\n",
    "    \"\"\"Apply function to estimate the URM retention\"\"\"\n",
    "    overall_grad, aa_h_grad, overall_retention = x\n",
    "    if np.isfinite(overall_grad) and np.isfinite(aa_h_grad) and np.isfinite(overall_retention):\n",
    "        overall_6yr_loss = 1 - overall_grad  # This number comes as a percentage\n",
    "        aa_h_6yr_loss = 1 - aa_h_grad  # This number comes as a percentage\n",
    "        overall_1yr_loss = 100 - overall_retention  # This number comes as 0-100\n",
    "        if (overall_6yr_loss > 0) & (aa_h_6yr_loss > 0):\n",
    "            aa_h_loss_as_share_of_overall = aa_h_6yr_loss / overall_6yr_loss\n",
    "            aa_h_retention = 100 - aa_h_loss_as_share_of_overall * overall_1yr_loss  # comes as 0-100\n",
    "            if (aa_h_retention > 0):\n",
    "                return int(np.round(aa_h_retention,decimals=0))\n",
    "            else:\n",
    "                return 0\n",
    "    return overall_retention\n",
    "df['Estimated AA_H Retention'] = df[['Adj 6yr Grad','Adj 6yr Grad AA_H','Retention']].apply(\n",
    "    calc_aa_h_retention, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, write the output\n",
    "writer = pd.ExcelWriter(cfg['output_file'], engine='xlsxwriter')\n",
    "wb = writer.book\n",
    "df.to_excel(writer, sheet_name=cfg['output_sheet_name'], na_rep='N/A')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From this point on, there is one manual change/addition:\n",
    "\n",
    "- add the 3+ schools not in NCES (Naval Prep, Arrupe, UIC Honors)\n",
    "\n",
    "### Two other stylistic steps:\n",
    "\n",
    "- Format the directory for sharing (including an external version without the Noble numbers)\n",
    "\n",
    "- (Step 5) Save off subsets of the data for use in college counseling tools--college lists, awards, Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
